{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data manipulation in Julia\n",
    "\n",
    "In this session, we will cover the basics of data manipulation in Julia, including\n",
    "- reading\n",
    "- merging/joining\n",
    "- summarizing/grouping\n",
    "- plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At the end of the class, you should be able to construct these plots:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <img src=\"figures/n_loglik_val_A.pdf\" style=\"width: 350px;\"/></td>\n",
    "<td> <img src=\"figures/n_loglik_val_F.pdf\" style=\"width: 350px;\"/></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We study the sparse inverse covariance problem and compare 3 methods: \n",
    "- Meinshausena and Buhlmann's approximation (BM)\n",
    "- Graphical Lasso (Glasso)\n",
    "- Discrete formulation (Big-M)\n",
    "\n",
    "We design experiments with \n",
    "- fixed dimension $p=200$\n",
    "- fixed underlying true sparsity $k_{true}=199$\n",
    "- varying number of samples $n$ (12 different values)\n",
    "\n",
    "We run each experiment $10$ times and want to report average results over all simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: Read the data\n",
    "\n",
    "We generate one CSV file per method (3) per experiment (12) and per simulation (10) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us look at the first CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using DataFrames, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "?CSV.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = CSV.read(\"experiment/baseline_BM_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "size(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let us have a look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "names(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first 4 columns identify the experiment and the simulation\n",
    " - :run is the number of the simulation (between 0 and 9)          \n",
    " - :p is the dimension of the problem             \n",
    " - :n is the number of samples            \n",
    " - :ktrue is the true sparsity pattern \n",
    "\n",
    "They take the same value for all rows in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The other columns correspond to the regularization path:\n",
    " - :lambda is the value of the regularization paramter       \n",
    " - :k is the sparsity of the corresponding estimator      \n",
    " - :time is the time needed to compute the solution       \n",
    " - :objval is the in-sample objective value\n",
    "\n",
    "Then, we report performance metrics that can be used for cross-validation:\n",
    " - :EBIC is the value of the in-sample Extended Bayesian Information Criterion (the lower the better)\n",
    " - :loglik_val is the value of the negative log-likelihood on the validation set (the lower the better)\n",
    "\n",
    "Finally, we report final metrics on the test set\n",
    " - :loglik_test is the negative log-likelihood on the test test\n",
    " - :TF is the number of true features selected          \n",
    " - :FF is the number of false features selected          \n",
    "\n",
    "We will not use the final 4 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Side note:** Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "DataFrames.rename(df, (:operatorNorm => :uselessColumn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But did not change the original table df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Suffix \"!\" denotes functions which modify their argument (convention only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "DataFrames.rename!(df, (:operatorNorm => :uselessColumn))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: Read/Concatenate \n",
    "\n",
    "> There are 120 files for the method \"BM\", write a Julia function which reads and concatenates all the CSV files into one dataframe\n",
    "\n",
    "> Note: you can concatenate dataframes horizontally (preserves the first dimension) or vertically (preserves the second dimension) using hcat(df1, df2) or vcat(df1, df2) respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function merge_files(prefix)\n",
    "    #write your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bm = merge_files(\"experiment/baseline_BM_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Define relevant columns\n",
    "\n",
    "In the end, we want to represent accuracy ($A$) and false detection rate ($F$) as a funtion of $n/p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: Add columns\n",
    "\n",
    "> Write a Julia function which takes a dataframe and add three columns: n/p, A and F.\n",
    "\n",
    "> Note:\n",
    "$$ A = \\dfrac{TF - p}{2 k_{true}}, \\quad F = \\dfrac{FF}{2 k} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function add_columns!(df)\n",
    "    #write your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "add_columns!(bm)\n",
    "bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Perform the CV\n",
    "\n",
    "For each experiment and simulation, we need to select the regularization parameter which minimizes the cross-validation criterion (either :EBIC or :loglik_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to use a \"group by\" strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "?DataFrames.groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gr = DataFrames.groupby(bm, [:run, :p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "creates a \"list of dataframes\", corresponding to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "length(gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can iterate over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for subgroup in gr\n",
    "    println(size(subgroup))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: Group by/Concatenate \n",
    "\n",
    "> Write a Julia function which takes as arguments\n",
    "- a dataframe, \n",
    "- the list of columns which define an experiment, \n",
    "- the column of the cross-validation criterion \n",
    "\n",
    "> and performs the cross validation for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function perform_cv(df, id_cols, crit_col)\n",
    "    #write your code here\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bm_cv = perform_cv(bm, [:run, :p, :n, :ktrue], :loglik_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "size(bm_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 4: Aggregate results\n",
    "\n",
    "For each experiment, we want to compute average accuracy and false detection (and their corresponding standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: Group by/Concatenate \n",
    "\n",
    "> Use a \"group by\" syntax to write a Julia function which takes as arguments\n",
    "- a dataframe, \n",
    "- the list of columns which define an experiment, \n",
    "\n",
    "> and returns a dataframe with average/standard deviation for A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "function aggregate_A(df, exp_cols)\n",
    "    #write your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_A(bm_cv, [:p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is already the second time we are writing a code like this: iterate over all subgroups, perform some data manipulations and concatenate results from each subgroups. There must be a better way! \n",
    "\n",
    "Indeed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "by(df, cols) do aux #Similar as \"for aux in groupby(df, cols)\"\n",
    "    #write all operations you want to do\n",
    "    #last line should be a dataframe\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is refered to as the **split-apply-combine** strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: \"Group by/Concatenate in one shot\" \n",
    "\n",
    "> Rewrite aggregate_A using a \"by(df, col) do ...\" syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "function aggregate_A2(df, exp_cols)\n",
    "    #write your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_A2(bm_cv, [:p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NB: Notice that this syntax always adds the columns you grouped on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yet, we still had to manually create columns. It can be tedious if you want to look at multiple outputs (A, F, time, loglik_test,...). There must be a better way!\n",
    "\n",
    "Indeed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "?DataFrames.aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: \"Aggregate\" \n",
    "\n",
    "> Rewrite aggregate_A2 using the aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "function aggregate_A3(df, exp_cols)\n",
    "    #write your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_A3(bm_cv, [:p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: \"Split-apply-combine\" strategy \n",
    "\n",
    "> Write a Julia function which takes a dataframe and returns summary statistics over all simulations for A, F, time and loglik_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "function aggregate_experiment(df, exp_cols)\n",
    "    by(df, exp_cols) do aux\n",
    "        aggregate(aux[:,[:ntop, :A, :F, :time]], :ntop, [mean, std])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_experiment(bm_cv, [:p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 5: Upload and process results for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bm = merge_files(\"experiment/baseline_BM_\") #1\n",
    "add_columns!(bm) #2\n",
    "bm_cv = perform_cv(bm, [:run, :p, :n, :ktrue], :loglik_val) #3\n",
    "bm_path = aggregate_experiment(bm_cv, [:p, :n, :ktrue]) #4\n",
    "\n",
    "glasso = merge_files(\"experiment/baseline_Glasso_\")\n",
    "add_columns!(glasso)\n",
    "glasso_cv = perform_cv(glasso, [:run, :p, :n, :ktrue], :loglik_val)\n",
    "glasso_path = aggregate_experiment(glasso_cv, [:p, :n, :ktrue])\n",
    "\n",
    "bigm = merge_files(\"experiment/n_bigm_\")\n",
    "add_columns!(bigm)\n",
    "bigm_cv = perform_cv(bigm, [:run, :p, :n, :ktrue], :loglik_val)\n",
    "bigm_path = aggregate_experiment(bigm_cv, [:p, :n, :ktrue])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 6: Plot\n",
    "\n",
    "Julia has a very nice plot package [**Plots.jl**](https://juliaplots.github.io). Plots.jl is an interface which sits on top of many backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Plots.pyplot() #pyplot backend\n",
    "Plots.plot(bm_path[:ntop], bm_path[:A_mean], yerr=bm_path[:A_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Plots.gr() #GR backend (default)\n",
    "Plots.plot(bm_path[:ntop], bm_path[:A_mean], yerr=bm_path[:A_std], label=\"MB\", xaxis=\"n/p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use the plot! function to modify the current plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Plots.plot!(bm_path[:ntop], bm_path[:F_mean], yerr=bm_path[:F_std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">**\\[Exercise\\]**: Plotting \n",
    "\n",
    "> Show on one graph how the accuracy $A$ evolves as $n/p$ increases for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Bonus: ** \n",
    "\n",
    "- Other syntax using the StatPlots package: [**StatPlots.jl**](https://github.com/JuliaPlots/StatPlots.jl) implements some useful recipes in data analysis and statistics\n",
    "- You can use LaTeX text in your legends using [**LaTeXStrings.jl**](https://github.com/stevengj/LaTeXStrings.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using StatPlots, LaTeXStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@df bm_path StatPlots.plot(:ntop, :A_mean, yerr=:A_std, label=\"MB\")\n",
    "@df glasso_path StatPlots.plot!(:ntop, :A_mean, yerr=:A_std, label=\"Glasso\")\n",
    "@df bigm_path StatPlots.plot!(:ntop, :A_mean, yerr=:A_std, label=\"Big-M\")\n",
    "xaxis!(L\"n/p\")\n",
    "yaxis!(L\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It can be tedious to write a line for each method specifically. It would be more efficient to:\n",
    "- add a column method to each dataframe\n",
    "- merge the three dataframes into one\n",
    "- use the method column as a group indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bm_path[:method] = \"MB\"\n",
    "glasso_path[:method] = \"Glasso\"\n",
    "bigm_path[:method] = \"Big-M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "big_df = vcat(bm_path, glasso_path)\n",
    "big_df = vcat(big_df, bigm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@df big_df StatPlots.plot(:ntop, :F_mean, yerr=:F_std, group=:method, line=1)\n",
    "xaxis!(L\"n/p\")\n",
    "yaxis!(L\"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus: Interoperability and RCall\n",
    "\n",
    "Julia has a growing number of packages implementing basic up to state-of-the-art statistics/ML techniques (e.g. GLM, GLMnet, LibLinear, ...) but is still a young programming language. \n",
    "\n",
    "**Good news!** If you ever need to, you can easily interact directly with R or Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "using RCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can easily write and compile R code with the Rstring syntaxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "R\"1+2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can use Julia objects in the R code using the \"$\" prefix\n",
    "\n",
    "Note: avoid using special characters for variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "R\"$big_df\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So if you\n",
    "- do not know how to do something in Julia\n",
    "- do know how to do it in R \n",
    "- are lazy to go from one language into another \n",
    "\n",
    "Simply use RCall!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "R\"\"\"\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "\n",
    "$big_df %>% \n",
    "    ggplot()+aes(x=ntop, y=F_mean, color=factor(method)) + geom_line()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Saving Julia objects using \n",
    "\n",
    "JLD/JLD2 enables to save/load Julia objects very easily (similar to pickle for Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using RCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@save \"test.jld2\" big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@load \"test.jld2\" big_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
